1. Introduction

Direct Liquid Cooling (DLC) is a cutting-edge cooling method used to manage the heat generated by high-performance GPUs. Optimizing cooling strategies is critical for reducing energy consumption, operational costs, and hardware degradation. Traditional cooling systems operate inefficiently by running at fixed rates, consuming unnecessary power during low workloads and failing to cool effectively during high-demand periods.

Artificial Intelligence (AI) provides a predictive and adaptive approach to cooling by forecasting energy consumption and dynamically adjusting cooling parameters. This report explores AI-based energy forecasting for DLC GPUs, compares different machine learning (ML) models, and presents a working Python implementation.
